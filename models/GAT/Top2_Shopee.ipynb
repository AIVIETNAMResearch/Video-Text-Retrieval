{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43960,"status":"ok","timestamp":1664260780638,"user":{"displayName":"Duy Do Le","userId":"16530654098807220295"},"user_tz":-420},"id":"b2SaavI3WxXO","outputId":"7c1a9df6-6d95-4834-f6b4-1efa0277ae07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12319,"status":"ok","timestamp":1664260823320,"user":{"displayName":"Duy Do Le","userId":"16530654098807220295"},"user_tz":-420},"id":"AKyj9Y3YmeQu","outputId":"93e13794-51c2-4d18-90fe-2d3ed6fdf581"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss_gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Installing collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n","\u001b[K     |████████████████████████████████| 509 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n","Installing collected packages: timm\n","Successfully installed timm-0.6.7\n"]}],"source":["!pip install faiss_gpu editdistance\n","!pip install timm\n","!pip install cupy"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee\n","\n","k = 50\n","conf_th = 0.7\n","\n","import pandas as pd\n","from pathlib import Path\n","\n","\n","def load_data():\n","    # nrows = 1000\n","    # df = pd.read_csv('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/train.csv', usecols=['posting_id', 'image', 'title'])\n","#         nrows = None\n","    df = pd.read_csv('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/train.csv', usecols=['posting_id', 'image', 'title']).append(\n","          pd.read_csv('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/train.csv', usecols=['posting_id', 'image', 'title'])).reset_index(drop=True)\n","    img_dir = Path('/content/drive/MyDrive/AIC_HCM/DOLG/DOLG-pytorch/dataset/data/train')\n","    return df, img_dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRHK7nvtruax","executionInfo":{"status":"ok","timestamp":1664246680974,"user_tz":-420,"elapsed":2094,"user":{"displayName":"Duy Do Le","userId":"16530654098807220295"}},"outputId":"82168ac6-1a8b-4d02-9cb7-059b3ca9763c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1m0rrLIYvPFV92b1Sh7VRMwu4Gyv4k4Vo/AIC_HCM/Video_Retrieval/Top2_Shopee\n"]}]},{"cell_type":"markdown","metadata":{"id":"vMZb1_9qmOMJ"},"source":["## GAT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVeyiA5jl8JO","colab":{"base_uri":"https://localhost:8080/","height":661},"outputId":"3305ecf7-e422-4cb9-bd21-c9c4804e490a","executionInfo":{"status":"ok","timestamp":1664248353193,"user_tz":-420,"elapsed":1672222,"user":{"displayName":"Duy Do Le","userId":"16530654098807220295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["68500\n","(68500, 3)\n","(68500, 68500)\n","(68500, 50)\n","[[    0 34250 67411 ... 46015 56472 22222]\n"," [    1 34251 52933 ... 10444 14206 48456]\n"," [    2 34252 49918 ... 37179 46093 11843]\n"," ...\n"," [68497 34247 57306 ... 53171 48952 14702]\n"," [68498 34248 13887 ... 11229 13554 47804]\n"," [68499 34249 68042 ...  4576 13998 48249]]\n","  load - done in 12.56996s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68500/68500 [03:16<00:00, 348.46it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["               posting_id posting_id_target      pred\n","0         train_129225211   train_378997795 -0.299922\n","1         train_129225211  train_3982974369 -0.299712\n","2         train_129225211  train_3829647969 -0.299964\n","3         train_129225211  train_2058577656 -0.299969\n","4         train_129225211   train_752725135 -0.299929\n","...                   ...               ...       ...\n","5745293  train_1792180725  train_1060076630 -0.299979\n","5745294  train_1792180725  train_1954734897 -0.299984\n","5745295  train_1792180725  train_2193000950 -0.299973\n","5745296  train_1792180725   train_511635458 -0.299985\n","5745297  train_1792180725   train_953530031 -0.299980\n","\n","[5745298 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-2566754d-2fee-4db9-ba11-d416012f5df1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>posting_id</th>\n","      <th>posting_id_target</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_129225211</td>\n","      <td>train_378997795</td>\n","      <td>-0.299922</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_129225211</td>\n","      <td>train_3982974369</td>\n","      <td>-0.299712</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_129225211</td>\n","      <td>train_3829647969</td>\n","      <td>-0.299964</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_129225211</td>\n","      <td>train_2058577656</td>\n","      <td>-0.299969</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_129225211</td>\n","      <td>train_752725135</td>\n","      <td>-0.299929</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5745293</th>\n","      <td>train_1792180725</td>\n","      <td>train_1060076630</td>\n","      <td>-0.299979</td>\n","    </tr>\n","    <tr>\n","      <th>5745294</th>\n","      <td>train_1792180725</td>\n","      <td>train_1954734897</td>\n","      <td>-0.299984</td>\n","    </tr>\n","    <tr>\n","      <th>5745295</th>\n","      <td>train_1792180725</td>\n","      <td>train_2193000950</td>\n","      <td>-0.299973</td>\n","    </tr>\n","    <tr>\n","      <th>5745296</th>\n","      <td>train_1792180725</td>\n","      <td>train_511635458</td>\n","      <td>-0.299985</td>\n","    </tr>\n","    <tr>\n","      <th>5745297</th>\n","      <td>train_1792180725</td>\n","      <td>train_953530031</td>\n","      <td>-0.299980</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5745298 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2566754d-2fee-4db9-ba11-d416012f5df1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2566754d-2fee-4db9-ba11-d416012f5df1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2566754d-2fee-4db9-ba11-d416012f5df1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["import sys\n","# sys.path.append('../input/timm045/')\n","import timm\n","\n","from itertools import zip_longest\n","import json\n","import math\n","import gc\n","import os\n","from pathlib import Path\n","\n","import faiss\n","import numpy as np\n","# import cupy as cp\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","from tqdm import tqdm\n","from PIL import Image\n","import joblib\n","import lightgbm as lgb\n","from scipy.sparse import hstack, vstack, csc_matrix, csr_matrix\n","import editdistance\n","import networkx as nx\n","\n","import string\n","import nltk\n","from nltk.tokenize.treebank import TreebankWordTokenizer\n","from nltk.tokenize import TweetTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","NUM_CLASSES = 11014\n","NUM_WORKERS = 2\n","SEED = 0\n","\n","class GraphDataset(Dataset):\n","\n","    def __init__(self, feats=None, labels=None, weights=None, pair_tuples=None, k=50, top_neighbors=None):\n","        self.feats = feats\n","        self.labels = labels\n","        self.weights = weights\n","        self.pair_tuples = pair_tuples\n","        self.k = k\n","        self.top_neighbors = top_neighbors\n","\n","    def __getitem__(self, index):\n","        i, j = self.pair_tuples[index]\n","        feat = torch.FloatTensor(self.feats[i][j])\n","\n","        padding_i = [[0] * feat.shape[0]] * (self.k - len(self.top_neighbors[i]))\n","        neighbor_feats_i = torch.FloatTensor([\n","            self.feats[i][neighbor]\n","            for neighbor in self.top_neighbors[i]\n","        ] + padding_i)\n","        padding_j = [[0] * feat.shape[0]] * (self.k - len(self.top_neighbors[j]))\n","        neighbor_feats_j = torch.FloatTensor([\n","            self.feats[j][neighbor]\n","            for neighbor in self.top_neighbors[j]\n","        ] + padding_j)\n","        neighbor_feats = torch.cat([feat.unsqueeze(0), neighbor_feats_i, neighbor_feats_j], dim=0)\n","\n","        outputs = (feat, neighbor_feats)\n","        if self.labels is not None:\n","            outputs += (self.labels[i] == self.labels[j],)\n","        if self.weights is not None:\n","            outputs += (self.weights[i],)\n","\n","        return outputs\n","\n","    def __len__(self):\n","        return len(self.pair_tuples)\n","\n","\n","class GraphAttentionLayer(nn.Module):\n","\n","    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n","        super().__init__()\n","        self.dropout = dropout\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.alpha = alpha\n","        self.concat = concat\n","\n","        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n","        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n","        self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)))\n","        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n","\n","        self.leakyrelu = nn.LeakyReLU(self.alpha)\n","\n","    def forward(self, h):\n","        Wh = h @ self.W  # h.shape: (B, N, in_features), Wh.shape: (B, N, out_features)\n","        a_input = self._prepare_attentional_mechanism_input(Wh)\n","        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(3))\n","\n","        attention = F.softmax(e, dim=1)\n","        attention = F.dropout(attention, self.dropout, training=self.training)\n","        h_prime = torch.bmm(attention, Wh)\n","\n","        if self.concat:\n","            return F.elu(h_prime)\n","        else:\n","            return h_prime\n","\n","    def _prepare_attentional_mechanism_input(self, Wh):\n","        B, N, D = Wh.shape\n","\n","        Wh_repeated_in_chunks = Wh.repeat_interleave(N, dim=1)\n","        Wh_repeated_alternating = Wh.repeat(1, N, 1)\n","\n","        all_combinations_matrix = torch.cat([Wh_repeated_in_chunks, Wh_repeated_alternating], dim=2)\n","        return all_combinations_matrix.view(-1, N, N, 2 * D)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n","\n","\n","class GATPairClassifier(nn.Module):\n","    def __init__(self, nfeat, nhid=8, nclass=1, dropout=0.6, alpha=0.2, nheads=8, pooling='first'):\n","        super().__init__()\n","        self.dropout = dropout\n","        self.pooling = pooling\n","\n","        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n","        for i, attention in enumerate(self.attentions):\n","            self.add_module('attention_{}'.format(i), attention)\n","\n","        self.out_att = GraphAttentionLayer(nhid * nheads, nhid, dropout=dropout, alpha=alpha, concat=False)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(nfeat + nhid, nhid),\n","            nn.PReLU(),\n","            nn.BatchNorm1d(nhid),\n","            nn.Linear(nhid, nclass),\n","        )\n","\n","    def forward_gat(self, x):\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = torch.cat([att(x) for att in self.attentions], dim=2)\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = F.elu(self.out_att(x))\n","        if self.pooling == 'first':\n","            return x[:, 0]\n","        elif self.pooling == 'mean':\n","            return x.mean(dim=1)\n","\n","    def forward(self, feats, neighbor_feats):\n","        gat_feats = self.forward_gat(neighbor_feats)\n","        cat_feats = torch.cat([feats, gat_feats], dim=1)\n","        return self.classifier(cat_feats).squeeze(1)\n","\n","\n","import time\n","from contextlib import contextmanager\n","from collections import defaultdict\n","map_used_time = defaultdict(float)\n","@contextmanager\n","def timer(title):\n","    t0 = time.time()\n","    yield\n","    tt = time.time() - t0\n","    map_used_time[title] += tt\n","    print(\"  {} - done in {:.5f}s\".format(title, tt))\n","\n","\n","df, img_dir = load_data()\n","\n","stop_words = set([\n","    'promo','diskon','baik','terbaik', 'murah',\n","    'termurah', 'harga', 'price', 'best', 'seller',\n","    'bestseller', 'ready', 'stock', 'stok', 'limited',\n","    'bagus', 'kualitas', 'berkualitas', 'hari', 'ini',\n","    'jadi', 'gratis',\n","])\n","\n","\n","titles = [\n","    title.translate(str.maketrans({_: ' ' for _ in string.punctuation}))\n","    for title in df['title'].str.lower().values\n","]\n","\n","# print(len(titles))\n","# print(df.shape)\n","tokenizer = TweetTokenizer()\n","tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, \n","                                   binary=True, \n","                                   min_df=2, \n","                                   token_pattern='(?u)\\\\b\\\\w+\\\\b', \n","                                   tokenizer=tokenizer.tokenize,\n","                                   dtype=np.float32,\n","                                   norm='l2')\n","tfidf_feats = tfidf_vectorizer.fit_transform(titles)\n","simmat_tfidf = tfidf_feats @ tfidf_feats.T\n","# print(simmat_tfidf.shape)\n","\n","with timer('load'):\n","    st_sizes, img_hs, img_ws = joblib.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/lyk_img_meta_data.pkl')\n","    similarities_img = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/img_D_qe.npy')[:, :k]\n","    indexes_img = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/img_I_qe.npy')[:, :k]\n","    # print(indexes_img.shape)\n","    # print(indexes_img)\n","\n","    similarities_bert = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/brt_D_qe.npy')[:, :k]\n","    indexes_bert = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/brt_I_qe.npy')[:, :k]\n","\n","    similarities_mm = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/mut_D_qe.npy')[:, :k]\n","    indexes_mm = np.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/mut_I_qe.npy')[:, :k]\n","    \n","    row = indexes_bert.ravel()\n","    col = np.arange(len(indexes_bert)).repeat(k)\n","    data = similarities_bert.ravel()\n","    simmat_bert = {(i, j): d for i, j, d in zip(col, row, data)}\n","\n","    row = indexes_img.ravel()\n","    col = np.arange(len(indexes_img)).repeat(k)\n","    data = similarities_img.ravel()\n","    simmat_img = {(i, j): d for i, j, d in zip(col, row, data)}\n","\n","    row = indexes_mm.ravel()\n","    col = np.arange(len(indexes_mm)).repeat(k)\n","    data = similarities_mm.ravel()\n","    simmat_mm = {(i, j): d for i, j, d in zip(col, row, data)}\n","\n","del row, col, data\n","gc.collect()\n","\n","ckpt = torch.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/v135.pth')\n","params = ckpt['params']\n","\n","top_neighbors = defaultdict(list)\n","feats = defaultdict(lambda: defaultdict())\n","\n","pair_tuples = []\n","for i in tqdm(range(len(df))):\n","    right_indexes = set(indexes_img[i, :k].tolist() + indexes_bert[i, :k].tolist())\n","    right_indexes.remove(i)  # remove self\n","\n","    right_indexes = list(right_indexes)\n","    # print('aaaaaaaaaaaa',len(right_indexes))\n","    # print(right_indexes)\n","    scores = {}\n","    for j in right_indexes:\n","        pair_tuples.append((i, j))\n","\n","        sim_img = simmat_img.get((i, j), 0)\n","        sim_bert = simmat_bert.get((i, j), 0)\n","        sim_mm = simmat_mm.get((i, j), 0)\n","        sim_tfidf = simmat_tfidf[i, j]\n","        if sim_img == 0 and sim_bert == 0:\n","            continue\n","\n","        feats[i][j] = [\n","            sim_img,\n","            sim_tfidf,\n","            sim_bert,\n","            sim_mm,\n","        ]\n","        scores[j] = sim_img + sim_tfidf + sim_bert + sim_mm\n","\n","    top_neighbors[i] = sorted(right_indexes, key=lambda x: scores[x], reverse=True)[:params['k']]\n","\n","dataset = GraphDataset(\n","    feats=feats,\n","    pair_tuples=pair_tuples,\n","    k=params['k'],\n","    top_neighbors=top_neighbors,\n",")\n","loader = DataLoader(dataset, batch_size=2 ** 5, shuffle=False, drop_last=False, num_workers=2, pin_memory=True)\n","\n","gat = GATPairClassifier(nfeat=len(feats[i][j]), nhid=params['nhid'],\n","                        dropout=params['dropout'], nheads=params['nheads'], pooling=params['pooling'])\n","gat.to('cuda').eval()\n","gat.load_state_dict(ckpt['model'])\n","\n","del tfidf_feats\n","gc.collect()\n","###\n","\n","preds = []\n","for feats, neighbor_feats in tqdm(loader, desc='predict', leave=False):\n","    feats = feats.to('cuda', non_blocking=True)\n","    neighbor_feats = neighbor_feats.to('cuda', non_blocking=True)\n","    with torch.no_grad():\n","        pred = gat(feats, neighbor_feats).sigmoid().detach().cpu().numpy().tolist()\n","        preds.extend(pred)\n","\n","conf_th_gcn = 0.3\n","df_pair = pd.DataFrame()\n","col, row = list(zip(*pair_tuples))\n","df_pair['i'] = col\n","df_pair['j'] = row\n","\n","df_pair['posting_id'] = df['posting_id'].values[df_pair['i'].values]\n","df_pair['posting_id_target'] = df['posting_id'].values[df_pair['j'].values]\n","\n","df_pair = df_pair[['posting_id', 'posting_id_target']]\n","df_pair['pred'] = preds\n","df_pair['pred'] -= conf_th_gcn\n","\n","# df_pair.to_pickle('submission_lyak_gcn.pkl')\n","df_pair"]},{"cell_type":"code","source":["# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"],"metadata":{"id":"irr-6M_gkoco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# checkpoint1 = torch.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/v45.pth')\n","# checkpoint3 = torch.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/v79.pth')\n","# params1 = checkpoint1['params']\n","# params3 = checkpoint3['params']\n","\n","# checkpoint2 = torch.load('/content/drive/MyDrive/AIC_HCM/Video_Retrieval/Top2_Shopee/features_npy/v34.pth')\n","# params2 = checkpoint2['params']\n","# print(params2['backbone'], params1['backbone'],params3['backbone'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sj3b7yTPhony","executionInfo":{"status":"ok","timestamp":1664261060058,"user_tz":-420,"elapsed":28105,"user":{"displayName":"Duy Do Le","userId":"16530654098807220295"}},"outputId":"8aa57818-4867-4b57-c3b6-645c64c89055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dm_nfnet_f0 vit_deit_base_distilled_patch16_384 dm_nfnet_f0\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}