{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import glob\n",
    "\n",
    "Database_path = '/media/nhattuong/Data/TranseNet/TransNet_Database'\n",
    "Databse_resize = '/media/nhattuong/Data/TranseNet/Database_resized_batch3/'\n",
    "\n",
    "img_paths = sorted(glob.glob(f'{Database_path}/KeyFramesC02_*/*/*.jpg'))\n",
    "\n",
    "for img_path in img_paths:\n",
    "    # if img_path.split('/')[-3] == 'KeyFramesC02_V01':\n",
    "    #     print('Skip')\n",
    "    #     continue\n",
    "\n",
    "    os.makedirs(Databse_resize + '/'.join(img_path.split('/')[-3:-1]), exist_ok=True)\n",
    "\n",
    "    des_path = Databse_resize + '/'.join(img_path.split('/')[-3:])\n",
    "\n",
    "    # if os.path.exists(des_path):\n",
    "    #     continue \n",
    "\n",
    "    print(\"des_path: \", des_path)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "\n",
    "    cv2.imwrite(des_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "list_csv_paths = '/media/nhattuong/Data/Dataset_BTC/keyframe_p_batch3'\n",
    "list_frame_paths = '/media/nhattuong/Data/TranseNet/TransNet_Database'\n",
    "\n",
    "lst_csv = glob(f'{list_csv_paths}/*.csv')\n",
    "print(\"lst_csv: \", lst_csv)\n",
    "lst_csv.sort()\n",
    "dct_names = {}\n",
    "\n",
    "for csv_path in tqdm(lst_csv):\n",
    "    df = pd.read_csv(csv_path,header = None)\n",
    "    for i in df.index:\n",
    "        row = df.loc[i]\n",
    "        video_id = csv_path.split('/')[-1][:-4]\n",
    "        key = f'{video_id}/{row[0]}'\n",
    "        value = f'{video_id}/{row[1]:06}.jpg' \n",
    "        dct_names[key] = value\n",
    "\n",
    "prev_keyframe = ''\n",
    "for key, value in tqdm(dct_names.items()):\n",
    "    keyframe = f'KeyFrames{key.split(\"/\")[0][:-2]}' # KeyFramesC00_V00\n",
    "    frame_src_path = f'{list_frame_paths}/{keyframe}/{keyframe}/{key}'\n",
    "    frame_dst_path = f'{list_frame_paths}/{keyframe}/{keyframe}/{value}'\n",
    "\n",
    "    print(frame_src_path, frame_dst_path)\n",
    "\n",
    "    if frame_src_path == frame_dst_path or not os.path.exists(frame_src_path):\n",
    "        continue\n",
    "\n",
    "    if prev_keyframe != keyframe:\n",
    "        lst_frame_in_video = os.listdir('/'.join(frame_src_path.split('/')[:-1]))\n",
    "        prev_keyframe = keyframe\n",
    "\n",
    "    # if frame_dst_path.split('/')[-1] in lst_frame_in_video:\n",
    "    #     os.remove(frame_src_path)\n",
    "    # else:\n",
    "    #     os.rename(frame_src_path, frame_dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Files for MutilModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1: 103108\n",
    "batch2: 88185\n",
    "batch3: 231239\n",
    "All: 422532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/nhattuong/Data/AIC_2022/dict_support_model'\n",
    "root_database = '/media/nhattuong/Data/Video-Text-Retrieval/Database'\n",
    "shot_frames_path = '/media/nhattuong/Data/Dataset/scenes_txt'\n",
    "\n",
    "count = 0\n",
    "debug = 0\n",
    "infos = []\n",
    "des_path = os.path.join(json_path, \"dict_support_model_batch.json\")\n",
    "keyframe_paths = sorted(glob.glob(f'{root_database}/KeyFramesC0*')) #_V01\n",
    "\n",
    "for kf in keyframe_paths:\n",
    "  video_paths = sorted(glob.glob(f\"{kf}/*\"))\n",
    "\n",
    "  for video_path in video_paths:\n",
    "    image_paths = sorted(glob.glob(f'{video_path}/*.jpg'))\n",
    "\n",
    "    ###### Get all id keyframes from video_path ######\n",
    "    id_keyframes = np.array([int(id.split('/')[-1].replace('.jpg', '')) for id in image_paths])\n",
    "\n",
    "    ###### Get scenes from video_path ######\n",
    "    video_info = video_path.split('/')[-1]\n",
    "    with open(f'{shot_frames_path}/{video_info}.txt', 'r') as f:\n",
    "      lst_range_shotes = f.readlines()\n",
    "    lst_range_shotes = np.array([re.sub('\\[|\\]', '', line).strip().split(' ') for line in lst_range_shotes]).astype(np.uint32)\n",
    "\n",
    "    for im_path in image_paths:\n",
    "      im_path = 'Database/' + '/'.join(im_path.split('/')[-3:])\n",
    "      id = int(im_path.split('/')[-1].replace('.jpg', ''))\n",
    "      \n",
    "      i = 0\n",
    "      flag=0\n",
    "      for range_shot in lst_range_shotes:\n",
    "        i+=1\n",
    "        first, end = range_shot\n",
    "\n",
    "        if first <= id <= end:\n",
    "          break\n",
    "        \n",
    "        if i == len(lst_range_shotes):\n",
    "          flag=1\n",
    "      \n",
    "      if flag == 1:\n",
    "        print(f\"Skip: {im_path}\")\n",
    "        print(first, end)\n",
    "        continue\n",
    "\n",
    "      ##### Get List Shot ID #####\n",
    "      lst_shot = id_keyframes[np.where((id_keyframes>=first) & (id_keyframes<=end))]\n",
    "      lst_shot = [f\"{i:0>6d}\" for i in lst_shot]\n",
    "\n",
    "      ##### Len > 7 #####\n",
    "      if len(lst_shot) > 7:\n",
    "        # print(lst_shot)\n",
    "        # print(im_path)\n",
    "\n",
    "        count_split = int(np.ceil(len(lst_shot)/7))\n",
    "        c = len(lst_shot)//count_split\n",
    "\n",
    "        # print(count_split, c)\n",
    "\n",
    "        for i in range(count_split):\n",
    "          if i + 1 == count_split:\n",
    "            lst_split = lst_shot[i*c:]\n",
    "          else:\n",
    "            lst_split = lst_shot[i*c:(i+1)*c]\n",
    "\n",
    "          # print(lst_split)\n",
    "          # print(len(lst_split)//2)\n",
    "          # print(lst_split.index(f\"{id:0>6d}\"))\n",
    "\n",
    "          try:\n",
    "            if len(lst_split)//2 == lst_split.index(f\"{id:0>6d}\"):\n",
    "              ##### Merge All Info #####\n",
    "              info = {\n",
    "                      \"image_path\": im_path,\n",
    "                      \"list_shot_id\": lst_split\n",
    "                      }\n",
    "                          \n",
    "              infos.append(info) \n",
    "              count += 1\n",
    "          except:\n",
    "            pass\n",
    "\n",
    "      else:\n",
    "        if len(lst_shot)//2 == lst_shot.index(f\"{id:0>6d}\"):\n",
    "          ##### Merge All Info #####\n",
    "          info = {\n",
    "                  \"image_path\": im_path,\n",
    "                  \"list_shot_id\": lst_shot\n",
    "                  }\n",
    "                      \n",
    "          infos.append(info) \n",
    "          count += 1\n",
    "\n",
    "id2img_fps = dict(enumerate(infos))\n",
    "\n",
    "with open(des_path, 'w') as f:\n",
    "  f.write(json.dumps(id2img_fps))\n",
    "\n",
    "print(f'Saved {des_path}')\n",
    "print(f\"Number of Index: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c040059c337deb504f19c673fdcf9a2751b584394b1f9883eb09580a791bf0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
