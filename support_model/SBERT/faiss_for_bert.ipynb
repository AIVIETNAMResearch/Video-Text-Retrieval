{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"Cô giáo đang ăn kem\", \"Chị gái đang thử món thịt dê\"]\n",
    "\n",
    "model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install faiss-gpu\n",
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install translate\n",
    "!pip install googletrans==3.1.0a0\n",
    "!pip install langdetect\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans\n",
    "import translate\n",
    "\n",
    "class Translation:\n",
    "    def __init__(self, from_lang='vi', to_lang='en', mode='google'):\n",
    "        # The class Translation is a wrapper for the two translation libraries, googletrans and translate. \n",
    "        self.__mode = mode\n",
    "        self.__from_lang = from_lang\n",
    "        self.__to_lang = to_lang\n",
    "\n",
    "        if mode in 'googletrans':\n",
    "            self.translator = googletrans.Translator()\n",
    "        elif mode in 'translate':\n",
    "            self.translator = translate.Translator(from_lang=from_lang,to_lang=to_lang)\n",
    "\n",
    "    def preprocessing(self, text):\n",
    "        \"\"\"\n",
    "        It takes a string as input, and returns a string with all the letters in lowercase\n",
    "        :param text: The text to be processed\n",
    "        :return: The text is being returned in lowercase.\n",
    "        \"\"\"\n",
    "        return text.lower()\n",
    "\n",
    "    def __call__(self, text):\n",
    "        \"\"\"\n",
    "        The function takes in a text and preprocesses it before translation\n",
    "        :param text: The text to be translated\n",
    "        :return: The translated text.\n",
    "        \"\"\"\n",
    "        text = self.preprocessing(text)\n",
    "        return self.translator.translate(text) if self.__mode in 'translate' \\\n",
    "                else self.translator.translate(text, dest=self.__to_lang).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFaiss:\n",
    "  def __init__(self, root_database: str, bin_file: str, json_path: str):    \n",
    "    self.index = self.load_bin_file(bin_file)\n",
    "    self.id2img_fps = self.load_json_file(json_path)\n",
    "\n",
    "    self.translater = Translation()\n",
    "    \n",
    "    self.__device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    self.model, preprocess = clip.load(\"ViT-B/16\", device=self.__device)\n",
    "    \n",
    "  def load_json_file(self, json_path: str):\n",
    "      with open(json_path, 'r') as f:\n",
    "        js = json.loads(f.read())\n",
    "\n",
    "      return {int(k):v for k,v in js.items()}\n",
    "\n",
    "  def load_bin_file(self, bin_file: str):\n",
    "    return faiss.read_index(bin_file)\n",
    "\n",
    "  def show_images(self, image_paths):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    columns = int(math.sqrt(len(image_paths)))\n",
    "    rows = int(np.ceil(len(image_paths)/columns))\n",
    "\n",
    "    for i in range(1, columns*rows +1):\n",
    "      img = plt.imread(image_paths[i - 1])\n",
    "      ax = fig.add_subplot(rows, columns, i)\n",
    "      ax.set_title('/'.join(image_paths[i - 1].split('/')[-3:]))\n",
    "\n",
    "      plt.imshow(img)\n",
    "      plt.axis(\"off\")\n",
    "      \n",
    "    plt.show()\n",
    "\n",
    "  def image_search(self, id_query, k):    \n",
    "    query_feats = self.index.reconstruct(id_query).reshape(1,-1)\n",
    "\n",
    "    scores, idx_image = self.index.search(query_feats, k=k)\n",
    "    idx_image = idx_image.flatten()\n",
    "\n",
    "    infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n",
    "    image_paths = [info['image_path'] for info in infos_query]\n",
    "    \n",
    "    # print(f\"scores: {scores}\")\n",
    "    # print(f\"idx: {idx_image}\")\n",
    "    # print(f\"paths: {image_paths}\")\n",
    "    \n",
    "    return scores, idx_image, infos_query, image_paths\n",
    "\n",
    "  def text_search(self, text, k):\n",
    "    if detect(text) == 'vi':\n",
    "      text = self.translater(text)\n",
    "\n",
    "    ###### TEXT FEATURES EXACTING ######\n",
    "    text = clip.tokenize([text]).to(self.__device)  \n",
    "    text_features = self.model.encode_text(text).cpu().detach().numpy().astype(np.float32)\n",
    "\n",
    "    ###### SEARCHING #####\n",
    "    scores, idx_image = self.index.search(text_features, k=k)\n",
    "    idx_image = idx_image.flatten()\n",
    "\n",
    "    ###### GET INFOS KEYFRAMES_ID ######\n",
    "    infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n",
    "    image_paths = [info['image_path'] for info in infos_query]\n",
    "    # lst_shot = [info['list_shot_id'] for info in infos_query]\n",
    "\n",
    "    # print(f\"scores: {scores}\")\n",
    "    # print(f\"idx: {idx_image}\")\n",
    "    # print(f\"paths: {image_paths}\")\n",
    "\n",
    "    return scores, idx_image, infos_query, image_paths\n",
    "\n",
    "  def write_csv(self, infos_query, scores, des_path):\n",
    "    video_names = []\n",
    "    frame_ids = []\n",
    "    score_ids = []\n",
    "\n",
    "    ### GET INFOS SUBMIT ###\n",
    "    for score, info in zip(scores.flatten().tolist(), infos_query):\n",
    "      video_name = info['image_path'].split('/')[-2] + '.mp4'\n",
    "      lst_frames = info['list_shot_id']\n",
    "\n",
    "      for id_frame in lst_frames:\n",
    "        video_names.append(video_name)\n",
    "        frame_ids.append(id_frame)\n",
    "        score_ids.append(score)\n",
    "\n",
    "    ### FORMAT DATAFRAME ###\n",
    "    check_files = {\"video_names\": video_names, \"frame_ids\": frame_ids, \"scores\": score_ids}\n",
    "    df = pd.DataFrame(check_files)\n",
    "    ###########################\n",
    "\n",
    "    ### Merge csv exist file to faiss search information ###\n",
    "    if os.path.exists(des_path):\n",
    "      df_exist = pd.read_csv(des_path, header=None, names=[\"video_names\", \"frame_ids\", \"scores\"])\n",
    "      \n",
    "      df.append(df_exist)\n",
    "\n",
    "    ### Return DataFrame with duplicate rows removed ###\n",
    "    df.drop_duplicates(subset=[\"video_names\", \"frame_ids\"], inplace=True)\n",
    "\n",
    "    ### Sort By Score ###\n",
    "    df.sort_values(by=['scores'])\n",
    "\n",
    "    ### Specifies up to 100 lines ###\n",
    "    if len(df) < 99:\n",
    "      df.to_csv(des_path, header=False, index=False)\n",
    "      print(f\"Save submit file to {des_path}\")\n",
    "    else:\n",
    "      print('Exceed the allowed number of lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSearch(MyFaiss):\n",
    "  def __init__(self, dict_bert_search='./keyframes_id_bert.json', bin_file='./faiss_bert.bin', mode='write'):\n",
    "    if mode in 'search':\n",
    "      self.model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "      \n",
    "      self.index = super().load_bin_file(bin_file)\n",
    "      self.id2img_fps = super().load_json_file(dict_bert_search)\n",
    "\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "  def create_files(self, des_json:str, dict_support_model:str, des_bin:str):\n",
    "    count = 0\n",
    "    self.infos = []\n",
    "\n",
    "    id2img_fps = super().load_json_file(dict_support_model)\n",
    "    npy_paths = sorted(glob.glob('/content/drive/MyDrive/ASR_Vietnamese_T/Embed*/*/*.npy'))\n",
    "\n",
    "    index = faiss.IndexFlatL2(768)\n",
    "\n",
    "    for npy_path in tqdm(npy_paths):\n",
    "      need_path = npy_path.split('/')[-1].replace('.npy','')\n",
    "\n",
    "      for id, values in id2img_fps.items():\n",
    "        image_path = values['image_path']\n",
    "        list_shot_id = values['list_shot_id']\n",
    "        start, end = int(list_shot_id[0]), int(list_shot_id[-1])\n",
    "\n",
    "        check_path = image_path.split('/')[-2] + f\"_{start}_{end}\"\n",
    "\n",
    "        if need_path == check_path:\n",
    "          info = {\n",
    "                  \"video_path\": '/'.join(image_path.split('/')[:-1]),\n",
    "                  \"list_shot_id\": list_shot_id\n",
    "                }\n",
    "\n",
    "          self.infos.append(info)\n",
    "          \n",
    "          try:\n",
    "            feat = np.load(npy_path)\n",
    "          except:\n",
    "            print(npy_path)\n",
    "\n",
    "          #### ADD FAISS ####\n",
    "          feat = feat.astype(np.float32).reshape(1,-1)\n",
    "          index.add(feat)  \n",
    "\n",
    "          #### Delete ID ####\n",
    "          id2img_fps.pop(id) # Delete an element from a dictionary \n",
    "          \n",
    "          count += 1\n",
    "\n",
    "          break\n",
    "              \n",
    "    results = dict(enumerate(self.infos))\n",
    "    \n",
    "    ##### SAVE JSON FILE #####\n",
    "    with open(des_json, 'w') as f:\n",
    "      f.write(json.dumps(results))\n",
    "\n",
    "    ##### SAVE BIN FILE #####\n",
    "    faiss.write_index(index, des_bin)\n",
    "    \n",
    "    ##### Print Infos Save #####\n",
    "    print(f'Saved {des_json}')\n",
    "    print(f\"Number of Index: {count}\")\n",
    "    print(f'Saved {des_bin}')\n",
    "\n",
    "  def bert_search(self, text, k):\n",
    "    ###### TEXT FEATURES EXACTING ######\n",
    "    text = [text, ]\n",
    "    text_features = model.encode(text)\n",
    "\n",
    "    ###### SEARCHING #####\n",
    "    scores, idx_image = self.index.search(text_features, k=k)\n",
    "    idx_image = idx_image.flatten()\n",
    "\n",
    "    infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n",
    "    image_paths = [info['image_path'] for info in infos_query]\n",
    "    \n",
    "    # print(f\"scores: {scores}\")\n",
    "    # print(f\"idx: {idx_image}\")\n",
    "    # print(f\"paths: {image_paths}\")\n",
    "    \n",
    "    return scores, idx_image, infos_query, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file = BERTSearch()\n",
    "create_file.create_files(des_json='/content/drive/MyDrive/keyframes_id_bert.json', dict_support_model='/content/drive/MyDrive/Video_Retrieval/dict_support_model/dict_support_model_batch.json', des_bin='/content/drive/MyDrive/faiss_bert.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybert = BERTSearch(dict_bert_search='/content/drive/MyDrive/keyframes_id_bert.json', bin_file='/content/drive/MyDrive/faiss_bert.bin', mode='search')\n",
    "\n",
    "text = 'Lũ lụt'\n",
    "\n",
    "scores, idx_image, infos_query, image_paths = mybert.bert_search(text, k=10)\n",
    "mybert.show_images(image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c040059c337deb504f19c673fdcf9a2751b584394b1f9883eb09580a791bf0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
