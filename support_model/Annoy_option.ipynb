{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annoy_Processing:\n",
    "  def __init__(self, root_database, json_path: str):\n",
    "    self.root_database = root_database\n",
    "    self.id2img_fps = self.load_json_file(json_path)\n",
    "\n",
    "    ## Scaling\n",
    "    self.sc = StandardScaler()\n",
    "    ## PCA\n",
    "    self.pca = PCA(n_components = 100)\n",
    "\n",
    "  def load_json_file(self, json_path: str):\n",
    "    with open(json_path, 'r') as f:\n",
    "      js = json.loads(f.read())\n",
    "\n",
    "    return {int(k):v for k,v in js.items()}\n",
    "\n",
    "  def buildAnnoyIndex(self, id_query, ls_id_db, metric, ntrees, feature_shape):\n",
    "    index = AnnoyIndex(feature_shape, metric)\n",
    "    \n",
    "    ####### MERGE ID_QUERY WTIH ID DATABASE #######\n",
    "    ls_id_db.insert(0, id_query)\n",
    "\n",
    "    ####### BUILD ANNOY #######\n",
    "    for id in range(len(ls_id_db)):\n",
    "      \"\"\"\n",
    "      Format Database:\n",
    "\n",
    "        Database/\n",
    "        │\n",
    "        ├── KeyFramesC00_V00/ \n",
    "        │   ├── C00_V0000/\n",
    "        │       └── 000000.jpg - Tất cả các KeyFrames được trích xuất từ videos\n",
    "        │\n",
    "        ├── CLIPFeatures_C00_V00/\n",
    "        │   └── C00_V0000.npy - Tất cả các CLIP Features của KeyFrames được lưu thành một file npy duy nhất\n",
    "\n",
    "      \"\"\"\n",
    "\n",
    "      ##### GET PATH NPY FILE #####\n",
    "      infos = self.id2img_fps[id] ## Get Infos from keyframe_id.json\n",
    "\n",
    "      image_path = infos[\"image_path\"] ## Ex: Database/KeyFramesC00_V00/C00_V0000/000000.jpg\n",
    "\n",
    "      batch_name = image_path.split('/')[-3].split('_')[-1] ## Ex: V00\n",
    "      video_id = re.sub('_V\\d+', '', image_path.split('/')[-2]) ## Ex: C00\n",
    "      clip_name = f\"CLIPFeatures_{video_id}_{batch_name}\" ## Ex: CLIPFeatures_C00_V00\n",
    "\n",
    "      npy_name = image_path.split('/')[-2] + '.npy' ## Ex: C00_V0000.npy\n",
    "\n",
    "      feat_path = os.path.join(self.root_database, clip_name, npy_name) ## Ex: Database/CLIPFeatures_C00_V00/C00_V0000.npy\n",
    "\n",
    "      ##### LOAD NPY FILE #####\n",
    "      feats = np.load(feat_path)\n",
    "      \n",
    "\n",
    "      # Scaling and PCA\n",
    "      # feats = self.sc.fit_transform(feats)\n",
    "      feats = self.pca.fit_transform(feats)\n",
    "      \n",
    "      # feats = self.sc.transform(feats)\n",
    "      # feats = pca.transform(feats)   \n",
    "\n",
    "      ##### GET ID IN NPY FILE #####\n",
    "      lst_id = os.listdir(re.sub('/\\d+.jpg','',image_path))\n",
    "      lst_id = sorted(lst_id, key=lambda x:int(x.split('.')[0]))\n",
    "\n",
    "      id_feats = lst_id.index(image_path.split('/')[-1])\n",
    "      \n",
    "      ##### GET FEATURES #####\n",
    "      feat = feats[id_feats]\n",
    "\n",
    "      ##### ADD FEATURE TO ANNOY #####\n",
    "      # feat = feat.astype(np.float32).reshape(1,-1)\n",
    "      index.add_item(id, feat)\n",
    "\n",
    "    ##### BUILD #####\n",
    "    index.build(ntrees)\n",
    "\n",
    "    return index\n",
    "\n",
    "  def annoy_search(self, id_query, list_id_database, metric, ntrees, topk, feature_shape=512):\n",
    "    ls_id_db = list_id_database.copy()\n",
    "    ##### Build Annoy #####\n",
    "    start_time = time.time()\n",
    "    annoy_idx = self.buildAnnoyIndex(id_query, ls_id_db, metric, ntrees, feature_shape)\n",
    "    print(f'Time Build for {len(list_id_database)+1} samples: {time.time()-start_time}')\n",
    "\n",
    "    ##### Searching #####\n",
    "    hit_id=0\n",
    "    Nb_neighbors=topk\n",
    "\n",
    "    start_time = time.time()\n",
    "    idx_image = annoy_idx.get_nns_by_item(hit_id, Nb_neighbors)\n",
    "    print(f'Time Search for Topk={topk}: {time.time()-start_time}')\n",
    "\n",
    "    ##### Get Infos #####\n",
    "    infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n",
    "    image_paths = [info['image_path'] for info in infos_query]\n",
    "\n",
    "    return idx_image, infos_query, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_database = '/content/drive/MyDrive/Merge_Database'\n",
    "json_path = '/content/drive/MyDrive/Video_Retrieval/faiss_merge_colab/keyframes_id.json'\n",
    "\n",
    "## Test Samples ##\n",
    "id_query = 0\n",
    "list_id_database = list(range(1,500))\n",
    "\n",
    "## Params ##\n",
    "metric = \"manhattan\"\n",
    "ntrees = 10\n",
    "topk = 200\n",
    "\n",
    "## Annoy ##\n",
    "my_annoy = Annoy_Processing(root_database, json_path)\n",
    "idx_image, infos_query, image_paths = my_annoy.annoy_search(id_query, list_id_database, metric, ntrees, topk=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  root_database = '/content/drive/MyDrive/Merge_Database'\n",
    "  json_path = '/content/drive/MyDrive/Video_Retrieval/faiss_merge_colab/keyframes_id.json'\n",
    "\n",
    "  ## Test Samples ##\n",
    "  id_query = 0\n",
    "  list_id_database = list(range(1,500))\n",
    "\n",
    "  ## Params ##\n",
    "  metric = \"manhattan\"\n",
    "  ntrees = 10\n",
    "  topk = 200\n",
    "\n",
    "  ## Annoy Implement ##\n",
    "  my_annoy = Annoy_Processing(root_database, json_path)\n",
    "  idx_image, infos_query, image_paths = my_annoy.annoy_search(id_query, list_id_database, metric, ntrees, topk=200, feature_shape=100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c040059c337deb504f19c673fdcf9a2751b584394b1f9883eb09580a791bf0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
